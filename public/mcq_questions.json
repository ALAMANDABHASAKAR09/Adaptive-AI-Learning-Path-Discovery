[
  {
    "id": "genai_b_001",
    "text": "What does 'Generative AI' primarily focus on creating?",
    "difficulty": 1,
    "tag": "Generative AI",
    "type": "MCQ",
    "options": [
      "Analyzing existing data",
      "Creating new content (text, images, etc.)",
      "Classifying data into categories",
      "Predicting future trends"
    ],
    "correctAnswer": "Creating new content (text, images, etc.)"
  },
  {
    "id": "genai_b_002",
    "text": "Which of these is a well-known example of a Generative AI model for text?",
    "difficulty": 1,
    "tag": "Generative AI",
    "type": "MCQ",
    "options": [
      "Linear Regression",
      "K-Means Clustering",
      "ChatGPT (GPT models)",
      "Decision Tree"
    ],
    "correctAnswer": "ChatGPT (GPT models)"
  },
  {
    "id": "genai_b_003",
    "text": "Tools like Midjourney and DALL-E are primarily used for generating what type of content?",
    "difficulty": 1,
    "tag": "Generative AI",
    "type": "MCQ",
    "options": [
      "Music",
      "Code",
      "Images",
      "Spreadsheets"
    ],
    "correctAnswer": "Images"
  },
  {
    "id": "genai_b_004",
    "text": "What is the typical input provided to a text-to-image Generative AI model?",
    "difficulty": 2,
    "tag": "Generative AI",
    "type": "MCQ",
    "options": [
      "A dataset of images",
      "A numerical code",
      "A text description (prompt)",
      "A pre-existing image"
    ],
    "correctAnswer": "A text description (prompt)"
  },
  {
    "id": "genai_b_005",
    "text": "What does 'LLM' stand for?",
    "difficulty": 1,
    "tag": "Generative AI",
    "type": "MCQ",
    "options": [
      "Large Logic Model",
      "Long Learning Machine",
      "Large Language Model",
      "Layered Language Module"
    ],
    "correctAnswer": "Large Language Model"
  },
  {
    "id": "genai_b_006",
    "text": "What is 'Prompt Engineering' primarily concerned with?",
    "difficulty": 2,
    "tag": "Prompt Engineering",
    "type": "MCQ",
    "options": [
      "Writing the AI model's code",
      "Designing the user interface",
      "Crafting effective inputs (prompts) for AI models",
      "Training the AI model on new data"
    ],
    "correctAnswer": "Crafting effective inputs (prompts) for AI models"
  },
  {
    "id": "genai_b_007",
    "text": "If you ask an LLM a question and it gives a factually incorrect but plausible-sounding answer, what is this phenomenon often called?",
    "difficulty": 3,
    "tag": "Generative AI",
    "type": "MCQ",
    "options": [
      "Overfitting",
      "Hallucination",
      "Underfitting",
      "Syntax Error"
    ],
    "correctAnswer": "Hallucination"
  },
  {
    "id": "genai_b_008",
    "text": "Which term refers to providing a few examples within the prompt itself to guide an LLM's output?",
    "difficulty": 3,
    "tag": "Prompt Engineering",
    "type": "MCQ",
    "options": [
      "Zero-Shot Prompting",
      "Fine-Tuning",
      "Few-Shot Prompting",
      "Reinforcement Learning"
    ],
    "correctAnswer": "Few-Shot Prompting"
  },
  {
    "id": "genai_c_003",
    "text": "What potential ethical issue arises when Generative AI is trained primarily on data from one demographic group?",
    "difficulty": 5,
    "tag": "AI Ethics",
    "type": "MCQ",
    "options": [
      "Model becomes too large",
      "Lack of representation and potential bias",
      "Requires specific hardware",
      "Cannot generate creative content"
    ],
    "correctAnswer": "Lack of representation and potential bias"
  },
  {
    "id": "rag_b_001",
    "text": "What does 'RAG' stand for in the context of LLMs?",
    "difficulty": 1,
    "tag": "RAG/Vector",
    "type": "MCQ",
    "options": [
      "Retrieval-Augmented Generation",
      "Random Access Generation",
      "Reinforced Attention Graph",
      "Rule-Applied Grammar"
    ],
    "correctAnswer": "Retrieval-Augmented Generation"
  },
  {
    "id": "rag_b_002",
    "text": "What is the main purpose of using RAG with an LLM?",
    "difficulty": 2,
    "tag": "RAG/Vector",
    "type": "MCQ",
    "options": [
      "To make the LLM faster",
      "To reduce the LLM's file size",
      "To allow the LLM to use external, up-to-date knowledge",
      "To translate text into different languages"
    ],
    "correctAnswer": "To allow the LLM to use external, up-to-date knowledge"
  },
  {
    "id": "rag_b_003",
    "text": "What kind of database is specifically designed to store and query vector embeddings efficiently?",
    "difficulty": 2,
    "tag": "RAG/Vector",
    "type": "MCQ",
    "options": [
      "SQL Database",
      "NoSQL Document Database",
      "Graph Database",
      "Vector Database"
    ],
    "correctAnswer": "Vector Database"
  },
  {
    "id": "rag_b_004",
    "text": "What does an 'embedding model' primarily do in a RAG pipeline?",
    "difficulty": 3,
    "tag": "RAG/Vector",
    "type": "MCQ",
    "options": [
      "Generates the final summary",
      "Stores the original PDF documents",
      "Converts text chunks into numerical vectors",
      "Filters out irrelevant keywords"
    ],
    "correctAnswer": "Converts text chunks into numerical vectors"
  },
  {
    "id": "rag_b_005",
    "text": "In RAG, the 'retrieval' step typically happens *before* or *after* the LLM generates the final answer?",
    "difficulty": 2,
    "tag": "RAG/Vector",
    "type": "MCQ",
    "options": [
      "Before",
      "After",
      "During",
      "It depends on the query"
    ],
    "correctAnswer": "Before"
  },
  {
    "id": "rag_c_004",
    "text": "What is the typical sequence of steps in a Retrieval-Augmented Generation (RAG) pipeline after receiving a user query?",
    "difficulty": 6,
    "tag": "RAG/Vector",
    "type": "MCQ-Reorder",
    "options": [
      "A) Generate Answer -> Retrieve Documents -> Embed Query",
      "B) Embed Query -> Retrieve Documents -> Generate Answer",
      "C) Retrieve Documents -> Generate Answer -> Embed Query",
      "D) Embed Query -> Generate Answer -> Retrieve Documents"
    ],
    "correctAnswer": "B) Embed Query -> Retrieve Documents -> Generate Answer"
  },
  {
    "id": "rag_d_004",
    "text": "You are building a RAG system for internal company documents containing sensitive PII. Which security measure is MOST critical during the indexing phase?",
    "difficulty": 8,
    "tag": "RAG/Vector",
    "type": "MCQ-Scenario",
    "options": [
      "A) Using the fastest available embedding model.",
      "B) Implementing robust access control lists (ACLs) on the source documents *before* indexing.",
      "C) Choosing a vector database with the highest query speed.",
      "D) Fine-tuning the LLM on company jargon."
    ],
    "correctAnswer": "B) Implementing robust access control lists (ACLs) on the source documents *before* indexing."
  },
  {
    "id": "lc_b_001",
    "text": "What is the primary goal of the Langchain library?",
    "difficulty": 2,
    "tag": "Langchain",
    "type": "MCQ",
    "options": [
      "To train large language models from scratch",
      "To provide a framework for building applications powered by LLMs",
      "To create optimized vector databases",
      "To automatically generate user interfaces"
    ],
    "correctAnswer": "To provide a framework for building applications powered by LLMs"
  },
  {
    "id": "lc_b_002",
    "text": "In Langchain, what core component represents a connection to an LLM (like OpenAI or a local model)?",
    "difficulty": 3,
    "tag": "Langchain",
    "type": "MCQ",
    "options": [
      "Agent",
      "Tool",
      "Chain",
      "Model I/O (LLM/ChatModel)"
    ],
    "correctAnswer": "Model I/O (LLM/ChatModel)"
  },
  {
    "id": "lc_b_003",
    "text": "What is a Langchain 'PromptTemplate' used for?",
    "difficulty": 3,
    "tag": "Langchain",
    "type": "MCQ",
    "options": [
      "Storing the LLM's response",
      "Defining reusable structures for creating prompts with variable inputs",
      "Connecting to external data sources",
      "Evaluating the output quality"
    ],
    "correctAnswer": "Defining reusable structures for creating prompts with variable inputs"
  },
  {
    "id": "lc_c_003",
    "text": "Which option correctly matches the Langchain component to its primary function?",
    "difficulty": 5,
    "tag": "Langchain",
    "type": "MCQ-Matching",
    "options": [
      "A) Agent : Stores conversation history",
      "B) Tool : Makes decisions on which action to take",
      "C) Memory : Connects to an external capability (like a calculator or API)",
      "D) Agent : Uses an LLM to decide which Tool(s) to use based on input"
    ],
    "correctAnswer": "D) Agent : Uses an LLM to decide which Tool(s) to use based on input"
  },
  {
    "id": "hf_b_001",
    "text": "What is the Hugging Face Hub primarily known for?",
    "difficulty": 2,
    "tag": "Huggingface",
    "type": "MCQ",
    "options": [
      "Cloud computing services",
      "A large repository of pre-trained AI models and datasets",
      "A Python IDE",
      "A project management tool"
    ],
    "correctAnswer": "A large repository of pre-trained AI models and datasets"
  },
  {
    "id": "dev_b_001",
    "text": "Which HTTP method is typically used to send data to an AI API endpoint to get a prediction or generation?",
    "difficulty": 2,
    "tag": "Development",
    "type": "MCQ",
    "options": [
      "GET",
      "POST",
      "DELETE",
      "PUT"
    ],
    "correctAnswer": "POST"
  },
  {
    "id": "dev_c_001",
    "text": "When integrating an LLM API into a Python application, what library is commonly used to make the HTTP requests?",
    "difficulty": 4,
    "tag": "Development",
    "type": "MCQ",
    "options": [
      "NumPy",
      "Pandas",
      "Requests",
      "Matplotlib"
    ],
    "correctAnswer": "Requests"
  },
  {
    "id": "cloud_b_001",
    "text": "Which Azure service is specifically designed for deploying and managing OpenAI models like GPT-4?",
    "difficulty": 3,
    "tag": "Cloud AI",
    "type": "MCQ",
    "options": [
      "Azure Functions",
      "Azure Blob Storage",
      "Azure OpenAI Service",
      "Azure Virtual Machines"
    ],
    "correctAnswer": "Azure OpenAI Service"
  },
  {
    "id": "deploy_b_001",
    "text": "What does 'latency' refer to when deploying an AI model as an API?",
    "difficulty": 2,
    "tag": "Deployment",
    "type": "MCQ",
    "options": [
      "The accuracy of the model",
      "The amount of data used for training",
      "The time it takes to get a response after sending a request",
      "The cost of running the model"
    ],
    "correctAnswer": "The time it takes to get a response after sending a request"
  },
  {
    "id": "train_b_001",
    "text": "What is the main goal of 'fine-tuning' a pre-trained language model?",
    "difficulty": 3,
    "tag": "Model Training",
    "type": "MCQ",
    "options": [
      "To make the model much larger",
      "To adapt the model to a specific task or domain",
      "To reduce the model's inference speed",
      "To erase its original training data"
    ],
    "correctAnswer": "To adapt the model to a specific task or domain"
  }
]
